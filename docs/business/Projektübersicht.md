

# ğŸ” **ProjektÃ¼bersicht: Self-Hosted AI Workspace Cloud mit OpenStack**

---

## ğŸ¯ **Projektziel**

Du planst den Aufbau einer **skalierbaren, sicheren und containerisierten AI-Workspace-Cloud** auf Basis von **OpenStack**. Ziel ist es, **Enterprise-Nutzern Ã¼ber den Browser eine vollstÃ¤ndige Linux-Desktopumgebung** mit zahlreichen AI- und Productivity-Tools bereitzustellen â€“ **pro Nutzer isoliert, GPU-beschleunigt, in VMs virtualisiert, services containerisiert**.

Langfristig soll das Setup auf **18 physische Nodes** skaliert werden, derzeit wird mit **2 leistungsstarken Servern + einem Raspberry Pi** eine **Testumgebung** aufgebaut.

---

## ğŸ—ï¸ **Zielarchitektur**

### ğŸ”§ Dienste pro User-Workspace (alle in Docker-Containern in der VM):

| Kategorie           | Services                                                 |
| ------------------- | -------------------------------------------------------- |
| **AI Services**     | Ollama (LLMs), Qdrant (Vector DB), Flowise, Open WebUI   |
| **Automation**      | N8N (Workflows)                                          |
| **Productivity**    | AppFlowy, AFFINE, OpenProject                            |
| **Developer Tools** | Zed Editor, GitLab CE                                    |
| **Search/Browser**  | SearXNG (metasuche), Supabase (BaaS), Langfuse (Logging) |

### ğŸ§‘â€ğŸ’¼ Nutzer erhalten:

* eine **vollstÃ¤ndige Desktop-VM** (z.â€¯B. Ubuntu XFCE via VNC/Web)
* Zugriff Ã¼ber **Browser (Guacamole oder Kasm)**
* Vorinstallierte Containerdienste je Service
* Zugriff auf `/shared`, Modellcache, Git-Projekte

---

## ğŸ§° **Kerntechnologien**

| Ebene                | Technologie                                 |
| -------------------- | ------------------------------------------- |
| **Virtualisierung**  | OpenStack (Nova, Glance, Neutron, Keystone) |
| **Netzwerk**         | Neutron (VXLAN), Floating IPs, NAT          |
| **Containerdienste** | Docker, Podman (in User-VMs)                |
| **Storage**          | Aktuell NFS via Raspberry Pi, spÃ¤ter Ceph   |
| **GPU**              | NVIDIA via passthrough (Ollama + LLMs)      |
| **Monitoring**       | Prometheus, Loki, Grafana, Alertmanager     |
| **Secrets**          | Vault (spÃ¤ter)                              |

---

## ğŸ“¦ **Hardwareplanung**

| Phase     | Ressourcen                                                                               |
| --------- | ---------------------------------------------------------------------------------------- |
| **Jetzt** | 2 Server (i7/i9 mit je 64 GB RAM, 1 GPU) + Pi 4                                          |
| **Ziel**  | 18 Nodes mit spezialisierter Rolle pro Node (GPU, Storage, Service, Control, Image Pool) |

> Besonderheit: Du willst **OpenStack direkt und vollstÃ¤ndig installieren**, nicht Ã¼ber DevStack oder Kolla.

---

## ğŸ“ **Storage Strategie**

### Jetzt:

* Raspberry Pi als NFS-Server oder MinIO fÃ¼r `/shared`, Modell-Cache, Backups

### SpÃ¤ter:

* **Ceph-Cluster (3+ Nodes)** fÃ¼r:

  * RBD Volumes (fÃ¼r Cinder)
  * CephFS (fÃ¼r Nutzer-Dateien)
  * RGW (fÃ¼r S3-kompatible Modelle, Logs)

**Anforderungen pro Ceph-Node:**

* 4â€“8 vCPU, 16â€“32 GB RAM, 2â€“4 Disks
* System-SSD 240â€“512 GB **nicht** fÃ¼r OSDs nutzen
* OSDs: 2Ã—4 TB HDDs empfohlen

---

## ğŸ§ª **Testumgebung (Ist-Zustand)**

| Node  | Rollen                               |
| ----- | ------------------------------------ |
| node1 | OpenStack Controller + Compute       |
| node2 | Compute + GPU (fÃ¼r Ollama etc.)      |
| rpi4  | NFS oder MinIO als einfacher Storage |

Ziel: Mit 2 Nodes vollstÃ¤ndigen Stack inkl. Floating IPs, VXLAN, Glance, Nova, Neutron und Horizon bereitstellen.

---

## ğŸ“¦ **Deploymentplan (Test zu Produktion)**

| Phase  | Inhalte                                                                 |
| ------ | ----------------------------------------------------------------------- |
| **1.** | Bare-Metal OpenStack Setup (keystone, nova, neutron, horizon)           |
| **2.** | Bereitstellung eines Golden Images (Ubuntu XFCE + Docker Compose Setup) |
| **3.** | Webzugriff Ã¼ber Guacamole                                               |
| **4.** | GPU-Passthrough + Containerized Ollama LLMs                             |
| **5.** | Einbindung rpi4 als NFS fÃ¼r `/shared` und Modell-Speicher               |
| **6.** | Service-Isolation pro Nutzer via Podman/Docker                          |
| **7.** | Observability via Prometheus + Loki                                     |
| **8.** | Migration auf Ceph + Multi-Node-Ausbau (3, 6, ... â†’ 18 Nodes)           |

---

## ğŸ” **Sicherheitsstrategie (vorgesehen)**

* Pro User eigene VM
* Keine Dienste exposed auÃŸer Ã¼ber Floating IP / Guacamole
* Auth via OpenStack/Keycloak/OAuth2-Proxy (optional)
* Ceph mit verschlÃ¼sselten OSDs (spÃ¤ter)
* Vault zur Secret-Verwaltung (spÃ¤ter)
* LLM-Monitoring mit Langfuse + Logging mit Loki

---

## ğŸ“„ NÃ¤chste Umsetzungsbausteine (bereitstellbar)

| Baustein                                  | Status / Anmerkung |
| ----------------------------------------- | ------------------ |
| `cloud-init`-VM-Image mit AI-Toolchain    | Bereitstellbar     |
| OpenStack-Ansible-Setup fÃ¼r 2 Nodes       | Bereitstellbar     |
| `docker-compose.yml` fÃ¼r alle AI-Services | Bereitstellbar     |
| `cephadm`-Bootstrap-Script fÃ¼r spÃ¤ter     | Bereitstellbar     |
| Guacamole + OAuth2-Proxy Deployment       | Bereitstellbar     |
| System-Partitionierungs-/fstab-Vorlage    | Bereitstellbar     |

---

## âœ… Empfohlener nÃ¤chster Schritt

**Empfehlung:**

> Starte mit einem **Golden Image mit cloud-init**, in dem **alle AI-Tools vorkonfiguriert sind**, um deine erste OpenStack-VM zu testen und den Nutzer-Workflow zu validieren.

Alternativ oder parallel:

* Konfiguriere Nova/Neutron und Floating IPs
* Bereite Guacamole-Zugang via VNC vor

---

### NÃ¤chste Schritte:

1. ğŸ–¥ï¸ `cloud-init`-fertiges AI-Desktop-Image?
2. âš™ï¸ `docker-compose.yml` fÃ¼r alle Tools in der VM?
3. ğŸ“œ OpenStack-Ansible-Setup fÃ¼r `node1` + `node2`?
4. ğŸ§Š Ceph-Cluster-Vorbereitung (3 Node-Simulation)?

